{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목</th>\n",
       "      <th>종목코드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>삼성전자</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>카카오</td>\n",
       "      <td>035720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>위메이드</td>\n",
       "      <td>112040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>현대차</td>\n",
       "      <td>005380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SK하이닉스</td>\n",
       "      <td>000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>카카오뱅크</td>\n",
       "      <td>323410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>한국조선해양</td>\n",
       "      <td>009540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARIRANG 고배당주</td>\n",
       "      <td>161510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NAVER</td>\n",
       "      <td>035420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>셀트리온</td>\n",
       "      <td>068270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LG화학</td>\n",
       "      <td>051910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HMM</td>\n",
       "      <td>011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>포스코케미칼</td>\n",
       "      <td>003670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>에디슨EV</td>\n",
       "      <td>161510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>셀트리온헬스케어</td>\n",
       "      <td>091990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>동진쎄미켐</td>\n",
       "      <td>005290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>기아</td>\n",
       "      <td>000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>카카오페이</td>\n",
       "      <td>377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>우리금융지주</td>\n",
       "      <td>316140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>펄어비스</td>\n",
       "      <td>263750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SK이노베이션</td>\n",
       "      <td>096770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>씨젠</td>\n",
       "      <td>096530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>기업은행</td>\n",
       "      <td>024110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>삼성전자우</td>\n",
       "      <td>005935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>삼화콘덴서</td>\n",
       "      <td>001820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SK바이오사이언스</td>\n",
       "      <td>302440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>아프리카TV</td>\n",
       "      <td>067160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>피에이치씨</td>\n",
       "      <td>057880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>텔레칩스</td>\n",
       "      <td>054450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>조아제약</td>\n",
       "      <td>034940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              종목    종목코드\n",
       "0           삼성전자  005930\n",
       "1            카카오  035720\n",
       "2           위메이드  112040\n",
       "3            현대차  005380\n",
       "4         SK하이닉스  000660\n",
       "5          카카오뱅크  323410\n",
       "6         한국조선해양  009540\n",
       "7   ARIRANG 고배당주  161510\n",
       "8          NAVER  035420\n",
       "9           셀트리온  068270\n",
       "10          LG화학  051910\n",
       "11           HMM  011200\n",
       "12        포스코케미칼  003670\n",
       "13         에디슨EV  161510\n",
       "14      셀트리온헬스케어  091990\n",
       "15         동진쎄미켐  005290\n",
       "16            기아  000270\n",
       "17         카카오페이  377300\n",
       "18        우리금융지주  316140\n",
       "19          펄어비스  263750\n",
       "20       SK이노베이션  096770\n",
       "21            씨젠  096530\n",
       "22          기업은행  024110\n",
       "23         삼성전자우  005935\n",
       "24         삼화콘덴서  001820\n",
       "25     SK바이오사이언스  302440\n",
       "26        아프리카TV  067160\n",
       "27         피에이치씨  057880\n",
       "28          텔레칩스  054450\n",
       "29          조아제약  034940"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/ps712/OneDrive/ps/aibi/snsstock/'\n",
    "path2='/Users/ps712/OneDrive/ps/aibi/snsstock/newsdata/'\n",
    "list_name = 'stock.csv'\n",
    "headers = {\"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\"}\n",
    "stock_list = pd.read_csv(os.path.join(path,list_name))\n",
    "stock_list['종목코드'] = stock_list['종목코드'].apply(lambda x : str(x).zfill(6))\n",
    "stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6bc56a7ac34081b5dbed5f6dc1ba1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "종목별 뉴스제목:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#articles =[]\n",
    "\n",
    "for code in notebook.tqdm(stock_list['종목코드'].values,\"종목별 뉴스제목\"):\n",
    "    company_code = code\n",
    "    result={}\n",
    "    title_result=[]\n",
    "    link_result =[]\n",
    "    date_results = []\n",
    "    source_results = []\n",
    "    df = pd.DataFrame()\n",
    "  \n",
    "    url = 'https://finance.naver.com/item/news_news.nhn?code=' + str(company_code) + '&page=1'\n",
    "    source_code = requests.get(url).text\n",
    "    html = BeautifulSoup(source_code,\"html.parser\")\n",
    "\n",
    "    lens = html.select('.pgRR')\n",
    "    for len in lens: \n",
    "        a = len.find('a')['href']\n",
    "    ab = int(a.split('=')[-1]) - 3\n",
    "\n",
    "    for i in range(0,ab):\n",
    "        page = i + 1   \n",
    "        url = 'https://finance.naver.com/item/news_news.nhn?code=' + str(company_code) + '&page=' + str(page) \n",
    "        source_code = requests.get(url).text\n",
    "        html = BeautifulSoup(source_code,\"html.parser\")\n",
    "        titles = html.select('.title')\n",
    "        \n",
    "        for title in titles: \n",
    "            title = title.get_text() \n",
    "            title = re.sub('\\n','',title)\n",
    "            title_result.append(title)\n",
    "\n",
    "        links = html.select('.title') \n",
    "        \n",
    "        for link in links: \n",
    "            add = 'https://finance.naver.com' + link.find('a')['href']\n",
    "            link_result.append(add)\n",
    "\n",
    "        dates = html.select('.date')\n",
    "        for date in dates:\n",
    "            date = date.get_text()\n",
    "            date_results.append(date)\n",
    "\n",
    "        sources = html.select('.info')\n",
    "        for source in sources:\n",
    "            source = source.get_text()\n",
    "            source_results.append(source)\n",
    "            \n",
    "        # for article in link_result:\n",
    "        #     headers = {\"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\"}\n",
    "        #     response = requests.post(article, headers=headers)\n",
    "        #     dom = BeautifulSoup(response.content.decode('euc-kr','replace'), \"html.parser\") \n",
    "        #     articles.append(dom.select_one(\"div#news_read\").get_text())\n",
    "        \n",
    "    result= {\"날짜\" : date_results, \"언론사\" : source_results, \"기사제목\" : title_result, \"링크\" : link_result} \n",
    "    df=pd.DataFrame(result)\n",
    "    df.to_csv(os.path.join(path2,company_code), encoding='utf8',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class news_crawler:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.company_code_table = pd.read_csv('company_list.txt', dtype=str, sep='\\t')\n",
    "\n",
    "\n",
    "    def crawler(self, company_code, num_article):\n",
    "\n",
    "        done_page_num=0\n",
    "\n",
    "        # page = 1\n",
    "        num_per_page=20 # naver serves 20 articles per page\n",
    "        num_page,remainder=divmod(num_article,20)\n",
    "        num_page+=1\n",
    "\n",
    "        article_result=[]\n",
    "\n",
    "        for page in range(done_page_num+1, done_page_num+num_page+1):\n",
    "            try:\n",
    "                url = 'https://finance.naver.com/item/news_news.nhn?code=' + str(company_code) + '&page=' + str(page)\n",
    "                source_code = requests.get(url).text\n",
    "                html = BeautifulSoup(source_code, \"html.parser\")\n",
    "\n",
    "\n",
    "                # 뉴스 링크\n",
    "                links = html.select('.title')\n",
    "\n",
    "                link_result =[]\n",
    "                if page == num_page:\n",
    "                    links=links[:remainder]\n",
    "\n",
    "                for link in links:\n",
    "                    add = 'https://finance.naver.com' + link.find('a')['href']\n",
    "\n",
    "                    link_result.append(add)\n",
    "\n",
    "                print(f\"{len(link_result)}개의 뉴스 크롤링..\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            for article_url in link_result:\n",
    "                try:\n",
    "                    article_source_code = requests.get(article_url).text\n",
    "                    article_html = BeautifulSoup(article_source_code, \"lxml\")\n",
    "                    article_time = article_html.select('.tah')[0].get_text()\n",
    "\n",
    "                    # 뉴스 내용\n",
    "                    article_contents = article_html.select('.scr01')\n",
    "                    article_contents=article_contents[0].get_text()\n",
    "                    article_contents = re.sub('\\n','',article_contents)\n",
    "                    article_contents = re.sub('\\t','',article_contents)\n",
    "\n",
    "                    # cut extra text after Copyright mark\n",
    "                    if \"ⓒ\" in article_contents:\n",
    "                        article_contents=article_contents[:article_contents.index(\"ⓒ\")]\n",
    "\n",
    "                    # cut too long text to prevent CUDA OOM issue\n",
    "                    if len(article_contents)>=1500:\n",
    "                        article_contents=article_contents[:1500]\n",
    "\n",
    "                    article_result.append([article_contents,article_time])\n",
    "\n",
    "                    time.sleep(random.uniform(0.1,0.7))\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # print(\"다운 받고 있습니다------\")\n",
    "\n",
    "        return article_result\n",
    "\n",
    "\n",
    "    def convert_company_to_code(self,company):\n",
    "\n",
    "        # 종목코드 추출\n",
    "        company_name = self.company_code_table['회사명']\n",
    "        keys = [i for i in company_name]    #데이터프레임에서 리스트로 바꾸기\n",
    "\n",
    "        company_code = self.company_code_table['종목코드']\n",
    "        values = [j for j in company_code]\n",
    "\n",
    "        dict_result = dict(zip(keys, values))  # 딕셔너리 형태로 회사이름과 종목코드 묶기\n",
    "\n",
    "        pattern = '[a-zA-Z가-힣]+'\n",
    "\n",
    "        if bool(re.match(pattern, company)) == True:\n",
    "            company_code = dict_result.get(str(company))\n",
    "            return company_code\n",
    "\n",
    "        else:\n",
    "            company_code = str(company)\n",
    "            return company_code\n",
    "\n",
    "    def crawl_news(self, company, max_num=5):\n",
    "        print(f\"{company} 종목 뉴스를 가져옵니다.\")\n",
    "        company_code=self.convert_company_to_code(company)\n",
    "\n",
    "        if company_code:\n",
    "                result=self.crawler(company_code, max_num)\n",
    "                for i in range(len(result)):\n",
    "                    result[i].append(company)\n",
    "                return result\n",
    "\n",
    "        else:\n",
    "            print(f\"{company} 종목이 존재하지 않습니다.\")   \n",
    "            return []"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b11d8b92d714ed8aec0b68e352f251beacbbe5b111f94024777877716d6a6c15"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('py39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
